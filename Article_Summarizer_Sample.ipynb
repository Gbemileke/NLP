{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are  [(0.06236571544671214, ['That’s', 'why,', 'until', 'we', 'have', 'a', 'national', 'privacy', 'law,', 'we', 'should', 'pursue', 'a', 'national', 'data', 'broker', 'registry', 'to', 'help', 'consumers', 'discover', 'this', 'information', '—', 'and', 'learn', 'the', 'difference', 'between', 'good', 'data', 'actors', 'and', 'bad', 'ones']), (0.05063736477894876, ['Our', 'business', 'is', 'underpinned', 'by', 'policies', 'on', 'comprehensive', 'data', 'governance,', 'in', 'an', 'effort', 'to', 'ensure', 'that', 'data', 'use', 'is', 'transparent,', 'fair', 'and', 'just,', 'that', 'there', 'are', 'benefits', 'for', 'both', 'businesses', 'and', 'consumers']), (0.04875760001041204, ['It’s', 'time', 'for', 'a', 'national', 'data', 'privacy', 'law,', 'one', 'that', 'gives', 'consumers', 'meaningful', 'rights', '—', 'to', 'know', 'who', 'has', 'their', 'data,', 'how', 'it', 'is', 'used', 'and', 'how', 'to', 'opt', 'out']), (0.048012906296338524, ['But', 'there', 'is', 'less', 'awareness', 'of', 'companies', '—', 'generally', 'referred', 'to', 'as', 'data', 'brokers', '—', 'that', 'collect,', 'source', 'and', 'otherwise', 'license', 'information', 'about', 'consumers', 'who', 'are', 'not', 'their', 'customers']), (0.0478312349916436, ['Increasing', 'transparency', '—', 'initially', 'through', 'a', 'data', 'broker', 'registry', 'and', 'ultimately', 'through', 'a', 'robust', 'and', 'balanced', 'national', 'privacy', 'law', '—', 'would', 'help', 'reduce', 'the', 'conflation', 'of', 'legitimate,', 'regulated', 'entities', 'with', 'unethical', 'companies', 'and', 'criminals']), (0.04678128288629835, ['It', 'would', 'also', 'give', 'individuals', 'the', 'tools', 'to', 'contact', 'companies', 'to', 'find', 'out', 'about', 'their', 'data', 'collection', 'practices,', 'as', 'well', 'as', 'information', 'about', 'how', 'to', 'opt', 'out', 'of', 'a', 'registered', 'company’s', 'marketing', 'products']), (0.04589624848701883, ['The', 'bill', 'would', 'require', 'data', 'brokers', 'to', 'sign', 'up', 'to', 'a', 'national', 'registry', 'overseen', 'by', 'the', 'Federal', 'Trade', 'Commission—', 'and', 'to', 'maintain', 'a', 'comprehensive', 'information', 'security', 'program', 'as', 'a', 'means', 'to', 'protect', 'consumer', 'data', 'from', 'security', 'breaches', 'and', 'other', 'inadvertent', 'or', 'improper', 'disclosures']), (0.04365015542018402, ['But', 'marketing', 'data', 'brings', 'real', 'value', 'to', 'consumers']), (0.0427476018973097, ['Still,', 'people', 'deserve', 'to', 'know', 'who', 'is', 'collecting', 'data', 'about', 'them,', 'why', 'it’s', 'being', 'collected', 'and', 'the', 'types', 'of', 'companies', 'with', 'which', 'the', 'data', 'is', 'being', 'shared']), (0.04109988362882206, ['They', 'should', 'also', 'have', 'assurances', 'that', 'companies', 'collecting', 'data', 'have', 'adequate', 'measures', 'in', 'place', 'to', 'ensure', 'security', 'and', 'confidentiality']), (0.03938596606730955, ['Consumers', 'demand', 'that', 'businesses', 'provide', 'them', 'with', 'more', 'transparency', 'around,', 'and', 'control', 'of,', 'their', 'data']), (0.0387853326680246, ['The', 'registry', 'would', 'identify', 'companies', 'that', 'collect', 'information', 'about', 'consumers', 'who', 'are', 'not', 'their', 'own', 'customers']), (0.038503048929680136, ['We', 'initially', 'resisted', 'the', 'Vermont', 'law', 'as', 'being', 'too', 'broad;', 'after', 'all,', 'providing', 'data', 'information', 'services', 'is', 'only', 'a', 'small', 'percentage', 'of', 'what', 'we', 'do']), (0.03329562992175786, ['Senator', 'Gary', 'Peters,', 'Democrat', 'of', 'Michigan,', 'and', 'Senator', 'Martha', 'McSally,', 'Republican', 'of', 'Arizona,', 'recently', 'introduced', 'the', 'Data', 'Broker', 'List', 'Act', 'of', '2019,', 'which', 'provides', 'a', 'helpful', 'starting', 'point', 'for', 'a', 'dialogue', 'around', 'a', 'national', 'data', 'broker', 'registry']), (0.031343854836620944, ['People', 'who', 'today', 'use', 'Facebook,', 'Google,', 'Amazon', 'and', 'Apple', 'understand', 'that', 'these', 'companies', 'collect', 'their', 'data', 'in', 'an', 'effort', 'to', 'improve', 'their', 'experience', 'and', 'to', 'generate', 'revenue', 'by', 'selling', 'advertising']), (0.030581827643369985, ['The', 'growing', 'commercial', 'use', 'of', 'data', 'is', 'outpacing', 'the', 'public’s', 'understanding']), (0.026733695540842393, ['Advertising', 'helps', 'consumers', 'get', 'relevant', 'information', 'to', 'assist', 'them', 'in', 'making', 'choices', 'on', 'an', 'endless', 'array', 'of', 'goods', 'and', 'services']), (0.025325754196163938, ['They', 'violate', 'consumers’', 'privacy,', 'profit', 'from', 'stolen', 'data', 'and', 'commit', 'fraud']), (0.02508955603529119, ['As', 'the', 'General', 'Data', 'Protection', 'Regulation', 'in', 'Europe', 'has', 'shown', 'us,', 'complexity', 'across', 'multiple', 'countries', 'and', 'standards', 'means', 'that', 'it', 'can', 'take', 'years', 'to', 'put', 'privacy', 'protections', 'in', 'place']), (0.023913702553653025, ['And', 'it', 'helps', 'our', 'clients', '—', 'in', 'sectors', 'like', 'financial', 'services', 'and', 'banking,', 'consumer', 'goods,', 'transportation', 'and', 'hospitality', '—', 'to', 'understand', 'customers', 'and', 'deliver', 'them', 'marketing', 'messages', 'that', 'are', 'more', 'relevant,', 'consistent', 'and', 'effective']), (0.022757189502624037, ['It’s', 'in', 'our', 'country’s', 'best', 'interest', 'to', 'have', 'a', 'national', 'standard', 'that,', 'done', 'thoughtfully,', 'benefits', 'both', 'consumers', 'and', 'businesses', 'by', 'providing', 'transparency,', 'uniformity', 'and', 'certainty', 'without', 'deterring', 'innovation', 'and', 'competition']), (0.020743772985835313, ['Many', 'different', 'constituencies', 'must', 'come', 'to', 'an', 'agreement', 'for', 'any', 'national', 'privacy', 'law', 'to', 'succeed']), (0.019835141698782994, ['There', 'is', 'much', 'work', 'to', 'do', 'to', 'ensure', 'the', 'ethical', 'use', 'of', 'information', 'in', 'our', 'economy']), (0.019358890181301568, ['A', 'comprehensive', 'national', 'privacy', 'law', 'cannot', 'be', 'developed', 'overnight,', 'especially', 'in', 'today’s', 'political', 'environment']), (0.018945423934766104, ['We', 'help', 'marketers', 'follow', 'the', 'golden', 'rule', 'of', 'business', '—', '“Know', 'Your', 'Customer”', '—', 'so', 'that', 'they', 'can', 'deliver', 'a', 'better', 'experience']), (0.017992832695845548, ['Laws', 'that', 'do', 'so', 'will', 'enable', 'us,', 'as', 'service', 'providers,', 'to', 'make', 'advertising', 'more', 'meaningful', 'for', 'consumers']), (0.01796113670459013, ['Data-driven', 'marketing', 'helps', 'businesses', 'reduce', 'wasteful', 'ad', 'spending', 'and', 'helps', 'fund', 'free', 'or', 'low-cost', 'consumer', 'products', 'and', 'services', 'on', 'the', 'internet,', 'including', 'free', 'search,', 'email', 'and', 'social', 'media', 'platforms,', 'as', 'well', 'as', 'customized', 'content']), (0.013642337598353663, ['That’s', 'why', 'it', 'is', 'important', 'that', 'regulations', 'reflect', 'the', 'dynamic', 'nature', 'of', 'data-driven', 'business', 'models', 'and', 'support', 'cutting-edge', 'services', 'and', 'products', 'across', 'the', 'digital', 'economy']), (0.0122265993084302, ['But', 'they', 'also', 'expect', 'continuous', 'innovation', 'and', 'progress']), (0.012038404107109171, ['In', 'many', 'cases,', 'it', 'also', 'funds', 'the', 'press', 'and', 'other', 'channels', 'of', 'expression']), (0.011856205998123585, ['Nonetheless,', 'we', 'believe', 'the', 'proposed', 'legislation', 'can', 'provide', 'a', 'solid', 'framework', 'for', 'the', 'necessary', 'development', 'of', 'a', 'registry', 'at', 'the', 'federal', 'level']), (0.008652543520870417, ['Only', 'Vermont', 'already', 'has', 'such', 'a', 'law,', 'although', 'other', 'states', 'are', 'considering', 'similar', 'measures']), (0.007751476073862567, ['And', 'quite', 'honestly,', 'it', 'shouldn’t', 'be', 'rushed;', 'there', 'are', 'complexities', 'to', 'consider,', 'such', 'as', 'the', 'role', 'of', 'existing', 'state', 'and', 'federal', 'laws,', 'as', 'well', 'as', 'which', 'agency', 'will', 'oversee', 'enforcement', 'and', 'how', 'it', 'will', 'be', 'funded']), (0.0054996834531031175, ['Unfortunately,', 'the', 'irresponsible', 'actions', 'of', 'some', 'individuals', 'and', 'organizations', 'have', 'cast', 'a', 'shadow', 'over', 'our', 'industry'])]\n",
      "Summarize Text: \n",
      " That’s why, until we have a national privacy law, we should pursue a national data broker registry to help consumers discover this information — and learn the difference between good data actors and bad ones\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize text\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "# let's begin\n",
    "generate_summary(\"TextAnalysis/article1.txt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
